import { NextRequest, NextResponse } from "next/server";
import fs from "node:fs/promises";
import path from "node:path";

export const runtime = "nodejs";

// Source of truth is a local JSON file generated by the cron script
// Fallback to parsing root README.md when JSON is unavailable

type LocalIssue = {
  id: number;
  title: string;
  html_url: string;
  updated_at: string;
  labels?: string[];
  repo?: string;
  org?: string;
  repo_name?: string;
  repo_stars?: number;
  repo_forks?: number;
  repo_pushed_at?: string;
};

type OrgSummary = {
  total_repos: number;
  total_stars: number;
  total_forks: number;
  recent_issues_count: number;
  activity_frequency: number;
  popularity_score: number;
};

type RepoSummary = {
  stars: number;
  forks: number;
  open_issues: number;
  pushed_at: string;
  updated_at: string;
  language: string;
  recent_issues_count: number;
};

export async function GET(request: NextRequest) {
  try {
    const { searchParams } = new URL(request.url);

    const language = searchParams.get("language") || "JavaScript"; // only used for README fallback heuristics
    const updatedSince = searchParams.get("updatedSince");
    const org = searchParams.get("org");
    const repo = searchParams.get("repo");
    const q = searchParams.get("q");
    const popularity = searchParams.get("popularity");
    const activity = searchParams.get("activity");
    const page = Number(searchParams.get("page") || "1");
    const per_page = Math.min(Number(searchParams.get("per_page") || "30"), 50);
    let issues: LocalIssue[] = [];

    // Fetch remote JSON as primary source
    const issuesJsonUrl = process.env.ISSUES_JSON_URL; // e.g. https://raw.githubusercontent.com/<org>/<repo>/main/web/public/issues.json
    const readmeRawUrl = process.env.README_RAW_URL;   // e.g. https://raw.githubusercontent.com/<org>/<repo>/main/README.md
    let orgSummaries: Record<string, OrgSummary> | undefined;
    let repoSummaries: Record<string, RepoSummary> | undefined;

    if (issuesJsonUrl) {
      try {
        const r = await fetch(issuesJsonUrl, { next: { revalidate: 60 } });
        if (r.ok) {
          const parsed = await r.json();
          issues = (parsed.items || []) as LocalIssue[];
          orgSummaries = parsed.org_summaries || undefined;
          repoSummaries = parsed.repo_summaries || undefined;
        }
      } catch {}
    }

    // Fallback: read local issues.json from repo root if available
    if (!issues || issues.length === 0) {
      try {
        const localIssuesPath = path.resolve(process.cwd(), "..", "issues.json");
        const file = await fs.readFile(localIssuesPath, "utf-8");
        const parsed = JSON.parse(file);
        const items = Array.isArray(parsed) ? parsed : parsed.items;
        if (Array.isArray(items)) {
          issues = items as LocalIssue[];
          orgSummaries = Array.isArray(parsed) ? undefined : parsed.org_summaries || undefined;
          repoSummaries = Array.isArray(parsed) ? undefined : parsed.repo_summaries || undefined;
        }
      } catch {}
    }
    // Fallback: fetch README.md remotely and parse
    if ((!issues || issues.length === 0) && readmeRawUrl) {
      try {
        const r = await fetch(readmeRawUrl, { next: { revalidate: 60 } });
        if (r.ok) {
          const md = await r.text();
          const lines = md.split("\n");
          let currentRepo: string | undefined;
          const repoHeaderRE = /^##\s+\[([^\]]+)\]\((https?:\/\/[^\)]+)\)/;
          const issueLineRE = /^\s*-\s\[(.+)\]\((https?:\/\/[^\)]+)\)/; // greedy title to handle nested brackets
          for (const raw of lines) {
            const line = raw.trim();
            if (!line) continue;
            const repoMatch = line.match(repoHeaderRE);
            if (repoMatch) {
              currentRepo = repoMatch[1];
              continue;
            }
            const issueMatch = line.match(issueLineRE);
            if (issueMatch && currentRepo) {
              const title = issueMatch[1].trim();
              const html_url = issueMatch[2].trim();
              issues.push({
                id: Math.abs((title + html_url).split("").reduce((a, c) => a + c.charCodeAt(0), 0)),
                title,
                html_url,
                updated_at: new Date().toISOString(),
                labels: [],
                repo: currentRepo,
              });
            }
          }
        }
      } catch {}
    }

    // Final fallback: parse local README.md from repo root
    if (!issues || issues.length === 0) {
      try {
        const readmePath = path.resolve(process.cwd(), "..", "README.md");
        const md = await fs.readFile(readmePath, "utf-8");
        const lines = md.split("\n");
        let currentRepo: string | undefined;
        const repoHeaderRE = /^##\s+\([^\)]+\)/; // placeholder, will be replaced below
        const repoHeaderFullRE = /^##\s+\[([^\]]+)\]\((https?:\/\/[^\)]+)\)/;
        const issueLineRE = /^\s*-\s\[(.+)\]\((https?:\/\/[^\)]+)\)/;
        for (const raw of lines) {
          const line = raw.trim();
          if (!line) continue;
          const repoMatch = line.match(repoHeaderFullRE);
          if (repoMatch) {
            currentRepo = repoMatch[1];
            continue;
          }
          const issueMatch = line.match(issueLineRE);
          if (issueMatch && currentRepo) {
            const title = issueMatch[1].trim();
            const html_url = issueMatch[2].trim();
            issues.push({
              id: Math.abs((title + html_url).split("").reduce((a, c) => a + c.charCodeAt(0), 0)),
              title,
              html_url,
              updated_at: new Date().toISOString(),
              labels: [],
              repo: currentRepo,
            });
          }
        }
      } catch {}
    }

    // Local filtering
    if (org) {
      issues = issues.filter((i) => (i.repo || "").startsWith(`${org}/`));
    }
    if (repo) {
      issues = issues.filter((i) => (i.repo || "").split("/")[1] === repo);
    }
    if (q) {
      const ql = q.toLowerCase();
      issues = issues.filter((i) =>
        (i.title || "").toLowerCase().includes(ql) || (i.repo || "").toLowerCase().includes(ql)
      );
    }
    if (updatedSince) {
      const since = new Date(updatedSince);
      issues = issues.filter((i) => new Date(i.updated_at) > since);
    }

    function popularityBucket(score?: number): "low" | "moderate" | "high" | "very_high" | undefined {
      if (typeof score !== "number" || !isFinite(score)) return undefined;
      if (score <= 100) return "low";
      if (score <= 1000) return "moderate";
      if (score <= 10000) return "high";
      return "very_high";
    }

    function activityBucket(freq?: number): "low" | "moderate" | "high" | "very_high" | undefined {
      if (typeof freq !== "number" || !isFinite(freq)) return undefined;
      if (freq < 2) return "low";
      if (freq < 5) return "moderate";
      if (freq < 15) return "high";
      return "very_high";
    }

    if (popularity) {
      issues = issues.filter((i) => {
        const orgKey = (i as any).org as string | undefined;
        const score = orgKey && orgSummaries ? orgSummaries[orgKey]?.popularity_score : (i as any).org_popularity_score;
        return popularityBucket(score) === popularity;
      });
    }
    if (activity) {
      issues = issues.filter((i) => {
        const orgKey = (i as any).org as string | undefined;
        const freq = orgKey && orgSummaries ? orgSummaries[orgKey]?.activity_frequency : (i as any).org_activity_frequency;
        return activityBucket(freq) === activity;
      });
    }

    // Sort and paginate locally, return minimal shape
    const result = issues
      .sort((a, b) => new Date(b.updated_at).getTime() - new Date(a.updated_at).getTime())
      .slice((page - 1) * per_page, (page - 1) * per_page + per_page)
      .map((i) => ({
        id: i.id,
        title: i.title,
        html_url: i.html_url,
        updated_at: i.updated_at,
        labels: (i.labels || []).filter(Boolean),
        repo: i.repo,
        org: i.org,
        repo_name: i.repo_name,
        repo_stars: typeof i.repo_stars === 'number' ? i.repo_stars : (i.repo && repoSummaries?.[i.repo]?.stars) || undefined,
        repo_forks: typeof i.repo_forks === 'number' ? i.repo_forks : (i.repo && repoSummaries?.[i.repo]?.forks) || undefined,
        repo_open_issues: i.repo && repoSummaries?.[i.repo]?.open_issues,
        repo_pushed_at: i.repo_pushed_at || (i.repo && repoSummaries?.[i.repo]?.pushed_at) || undefined,
        org_activity_frequency: i.org && orgSummaries?.[i.org]?.activity_frequency,
        org_popularity_score: i.org && orgSummaries?.[i.org]?.popularity_score,
        org_total_stars: i.org && orgSummaries?.[i.org]?.total_stars,
        org_total_forks: i.org && orgSummaries?.[i.org]?.total_forks,
      }));

    return NextResponse.json({ items: result });
  } catch (e: any) {
    return NextResponse.json({ error: e?.message || "Unknown error" }, { status: 500 });
  }
}


